{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
      "Species:  ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# for time being - we will use the famous.. Iris dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "print('URL:', url)\n",
    "\n",
    "col_names = ['sepal_length', 'sepal_width','petal_length','petal_width','species']\n",
    "df = pd.read_csv(url, header=None, names=col_names, encoding='utf-8')\n",
    "\n",
    "# we have 'Iris-setosa', 'Iris-versicolor', and 'Iris-virginica' \n",
    "# species; we will convert it to numeric as labels\n",
    "print('Species: ', df['species'].unique())\n",
    "\n",
    "df.loc[(df['species'] == 'Iris-setosa', 'species')] = 0\n",
    "df.loc[(df['species'] == 'Iris-versicolor', 'species')] = 1\n",
    "df.loc[(df['species'] == 'Iris-virginica', 'species')] = 2\n",
    "\n",
    "df = df.rename(columns={\"species\": \"label\"})\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our dataset to train and test randomly\n",
    "def train_test_split(X, y, test_size = 0.3):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(X))\n",
    "\n",
    "    indices = [*range(len(X))]\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "    \n",
    "    X_test = X[test_indices].astype('float')\n",
    "    y_test = y[test_indices].astype('int')\n",
    "    \n",
    "    X_train = np.delete(X, test_indices, axis=0).astype('float')\n",
    "    y_train = np.delete(y, test_indices, axis = None).astype('int')\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:4].values\n",
    "y = df.iloc[:,4].values\n",
    "\n",
    "random.seed(0) # random seed to reproduce our results\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(object):\n",
    "    def __init__(self, max_depth = 5):\n",
    "        self.depth = 0\n",
    "        self.max_depth = max_depth # define the node levels\n",
    "        self.infogain = dict()\n",
    "    \n",
    "    def fit(self, x, y, root_node={}, depth=0):    \n",
    "        # checking if all our labels is the same otherwise we are done here\n",
    "        all_same = all(i == y[0] for i in y)\n",
    "    \n",
    "        if all_same:\n",
    "            return {'class':y[0]}\n",
    "        elif len(y) == 0:\n",
    "            return None\n",
    "        elif root_node is None: \n",
    "            return None\n",
    "        elif depth >= self.max_depth:\n",
    "            print('Fucking Bitch')\n",
    "            return None\n",
    "       \n",
    "        if len(self.infogain) == 0:\n",
    "            # compute our information gain\n",
    "            self.infogain = self.getInfoGain(y)\n",
    "    \n",
    "        # split by the lowest entropy\n",
    "        att, condition, entropy, infogain, gainratio = self.splitAttribute(x, y)     \n",
    "        #print(entropy)\n",
    "        root_node = {'attribute': col_names[att], 'index_att':att,\n",
    "                     'condition':condition,'class': np.round(np.mean(y))} # for multiclass, take the average\n",
    "\n",
    "        # using recursion, we wil run the fit function on our left and right node..\n",
    "        y_left = y[x[:, att] < condition]\n",
    "        x_left = x[x[:, att] < condition]\n",
    "\n",
    "        y_right = y[x[:, att] >= condition]\n",
    "        x_right = x[x[:, att] >= condition]\n",
    "\n",
    "        root_node['left_node'] = self.fit(x_left, y_left, {}, depth+1)\n",
    "        root_node['right_node'] = self.fit(x_right, y_right, {}, depth+1)\n",
    "\n",
    "        self.depth += 1    # increase the depth of our tree\n",
    "        self.root_node = root_node  # store our tree\n",
    "        return root_node\n",
    "    \n",
    "    \n",
    "    def getInfoGain(self, y):\n",
    "        num = len(y)\n",
    "        infogain = dict()\n",
    "        for label in set(y):\n",
    "            positive = sum(y==label) # true\n",
    "            negative = sum(y!=label) # false\n",
    "            ent = self.entropyCalc(positive, negative) \n",
    "            infogain[label] = ent\n",
    "        return infogain\n",
    "    \n",
    "    def splitAttribute(self, x, y):\n",
    "        att = None \n",
    "        condition = None\n",
    "        infogain = self.infogain\n",
    "        min_entropy = 1\n",
    "        max_gain = 0 \n",
    "        max_infogain= 0\n",
    "        for i, c in enumerate(x.T):\n",
    "            # loop per attribute to find the best feature to split\n",
    "            ent, condition_test = self.getMinimumEntropy(c, y)\n",
    "            if ent == 0:# return if entropy is zero\n",
    "                return i, condition_test, ent, max_infogain, max_gain\n",
    "            \n",
    "            \n",
    "            # find the minimum_entropy\n",
    "            if ent <= min_entropy:\n",
    "                overall_infogain = []\n",
    "                for label in set(y):\n",
    "                        overall_infogain.append(infogain[label] - ent)\n",
    "                max_infogain = max(overall_infogain)\n",
    "                # retrieve maximum information gain        \n",
    "                split_info = self.getSplitInfo(c, y, i, condition_test)    \n",
    "                gain = self.getGainRatio(max_infogain, split_info)\n",
    "                if gain > max_gain:\n",
    "                    att = i\n",
    "                    min_entropy = ent\n",
    "                    max_infogain = max_infogain\n",
    "                    max_gain = gain\n",
    "                    condition = condition_test\n",
    "                \n",
    "                \n",
    "        return att, condition, min_entropy, max_infogain, max_gain\n",
    "    \n",
    "    def getSplitInfo(self, x, y, att, condition): #C4.5\n",
    "        if len(y) == 0:\n",
    "            return None\n",
    "        \n",
    "        y_num = len(y)    \n",
    "        y_left = len(y[x < condition])\n",
    "        y_right = len(y[x >= condition])\n",
    "\n",
    "        if y_left == 0:\n",
    "            left_split = 0\n",
    "        else:    \n",
    "            left_split = -(y_left/y_num)* math.log(y_left/y_num, 2)\n",
    "        if y_left == 0:\n",
    "            right_split = 0\n",
    "        else:       \n",
    "            right_split = -(y_right/y_num)* math.log(y_right/y_num, 2)\n",
    "        \n",
    "        return left_split + right_split\n",
    "        \n",
    "        \n",
    "    def getGainRatio(self, max_infogain, split_info):\n",
    "        if split_info == 0: \n",
    "            return 0\n",
    "        return max_infogain/split_info\n",
    "    \n",
    "    \n",
    "    def getMinimumEntropy(self, att, y):\n",
    "        n = len(y)\n",
    "        minimum_entr = 1\n",
    "        # loop trought unique value and find the lowest entrophy\n",
    "        for value in set(att):\n",
    "            y_pred = att < value\n",
    "            # retrieve our entropy on each attributes\n",
    "            entr = self.getEntropy(y_pred, y)\n",
    "            if entr <= minimum_entr:\n",
    "                condition = value\n",
    "                minimum_entr = entr\n",
    "        return minimum_entr, condition\n",
    "    \n",
    "    def getEntropy(self, y_pred, y): \n",
    "        # this will get me the entropy on the possible split\n",
    "        num = len(y)\n",
    "        # calculate the entropy left_node and right_node entropy\n",
    "        entrophy_positive, num_positive = self.entropyNode(y[y_pred])\n",
    "        entrophy, num_negative = self.entropyNode(y[~y_pred]) \n",
    "        # overall entropy\n",
    "        overall_entropy = num_positive/num * entrophy_positive + num_negative/num * entrophy\n",
    "        \n",
    "        return overall_entropy\n",
    "    \n",
    "    def entropyNode(self, labels): \n",
    "        total_entropy = 0\n",
    "        num = len(labels)\n",
    "        classes = set(labels)\n",
    "        #compute each entrophy; example from the slides:\n",
    "        #     E(P_Usage) = 6/15 I(1,5) + 6/15 I(5,1) + 3/15 I(3,0)\n",
    "        for label in classes:   \n",
    "            positive = sum(labels==label) # true\n",
    "            negative = sum(labels!=label) # false\n",
    "            ent = positive/num * self.entropyCalc(positive, negative) \n",
    "            total_entropy += ent\n",
    "        return total_entropy, num\n",
    "    \n",
    "    def entropyCalc(self, positive, negative):\n",
    "        # if one contains all the same classes, entropy will return 0\n",
    "        if positive== 0 or negative == 0: \n",
    "            return 0\n",
    "        num = positive + negative\n",
    "\n",
    "        # calculate the info gain with entropy \n",
    "        positive_side = -(positive/num) * math.log(positive/num, 2)\n",
    "        negative_side = -(negative/num) * math.log(negative/num, 2)\n",
    "    \n",
    "        return positive_side + negative_side\n",
    "                                      \n",
    "    def predict(self, x):\n",
    "        tree = self.root_node\n",
    "        \n",
    "        result = np.array([0]*len(x))\n",
    "        for i, c in enumerate(x):\n",
    "            result[i] = self.parseTree(c)\n",
    "        return result\n",
    "    \n",
    "    def parseTree(self, row):\n",
    "        tree = self.root_node\n",
    "        #pprint.pprint(tree)\n",
    "        # simply traverse down the tree on each attribute\n",
    "        while tree.get('condition', {}):\n",
    "            if row[tree['index_att']] < tree['condition']:\n",
    "                tree = tree['left_node']\n",
    "            else:\n",
    "                tree = tree['right_node']\n",
    "        else:\n",
    "            return tree.get('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attribute': 'petal_length',\n",
      " 'class': 1.0,\n",
      " 'condition': 3.3,\n",
      " 'index_att': 2,\n",
      " 'left_node': {'class': 0},\n",
      " 'right_node': {'attribute': 'petal_width',\n",
      "                'class': 2.0,\n",
      "                'condition': 1.7,\n",
      "                'index_att': 3,\n",
      "                'left_node': {'attribute': 'petal_length',\n",
      "                              'class': 1.0,\n",
      "                              'condition': 5.0,\n",
      "                              'index_att': 2,\n",
      "                              'left_node': {'class': 1},\n",
      "                              'right_node': {'attribute': 'petal_width',\n",
      "                                             'class': 2.0,\n",
      "                                             'condition': 1.6,\n",
      "                                             'index_att': 3,\n",
      "                                             'left_node': {'class': 2},\n",
      "                                             'right_node': {'class': 1}}},\n",
      "                'right_node': {'class': 2}}}\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "result = dt.fit(X_train, y_train)\n",
    "pprint.pprint(result)\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       0.93      1.00      0.97        14\n",
      "Iris-versicolor       0.93      0.82      0.87        17\n",
      " Iris-virginica       0.87      0.93      0.90        14\n",
      "\n",
      "       accuracy                           0.91        45\n",
      "      macro avg       0.91      0.92      0.91        45\n",
      "   weighted avg       0.91      0.91      0.91        45\n",
      "\n",
      "Accuracy score:  0.9111111111111111\n",
      "Misclassified examples: 4\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica' ]\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "print('Accuracy score: ', (y_test == y_pred).sum() / len(y_test))\n",
    "print('Misclassified examples: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier(object):\n",
    "    def __init__(self,unique_classes = None):\n",
    "        self.classes=unique_classes \n",
    "\n",
    "    def combineData(self, X, y):\n",
    "        # combmine our attributes and labels\n",
    "        dataset = []\n",
    "        for i in range(len(X)):\n",
    "            dataset.append(X[i].tolist()+[y[i]])\n",
    "        return dataset\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if len(X)==0 or len(y) == 0:\n",
    "            return None\n",
    "        elif X is None or y is None:\n",
    "            return 0\n",
    "        else:\n",
    "            datasets = self.combineData(X, y)\n",
    "            \n",
    "            # training phase which returns the prior probability on each labels\n",
    "            self.model = self.infoPerClass(datasets)\n",
    "            return self.model\n",
    "        \n",
    "    def infoCalc(self, datasets):\n",
    "        info = []\n",
    "        # calculate the mean, standard deviation and count for each dataset\n",
    "        for col in zip(*datasets):\n",
    "            info.append([np.mean(col), np.std(col), len(col)])\n",
    "        info.remove(info[-1])\n",
    "        return info\n",
    "\n",
    "    def infoPerClass(self,datasets):\n",
    "        # collect all dataset on each labels\n",
    "        label_sets = self.datasetPerClass(datasets)\n",
    "        \n",
    "        info = dict() # info of each class\n",
    "        for label, data in label_sets.items():\n",
    "            info[label] = self.infoCalc(data)\n",
    "        return info\n",
    "    \n",
    "    def datasetPerClass(self, datasets):\n",
    "        # collect all dataset on each labels\n",
    "        label_sets = dict() # used dictionary to return\n",
    "        for i, c in enumerate(datasets):\n",
    "            label = c[-1] # last column is our labels\n",
    "            if (label not in label_sets):\n",
    "                label_sets[label] = list() # create a list in the dictionary\n",
    "            label_sets[label].append(c)\n",
    "        return label_sets\n",
    "\n",
    "    def calcProb(self, x, mean, stdev):\n",
    "        exponent = math.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "    def calcClassProb(self, row):\n",
    "        summaries = self.model\n",
    "        \n",
    "        totals = []\n",
    "        for label in summaries:\n",
    "            totals.append(summaries[label][0][2])\n",
    "        total_rows = sum(totals)\n",
    "        \n",
    "        probabilities = dict()\n",
    "        for class_value, class_summaries in summaries.items():\n",
    "            probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "            \n",
    "            # calculate the probabilities on each testing set\n",
    "            for i in range(len(class_summaries)):\n",
    "                mean, stdev, _ = class_summaries[i]\n",
    "                probabilities[class_value] *= self.calcProb(row[i], mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        row = X_test.tolist()\n",
    "        label=[]\n",
    "        # iterate our testing set and get the likehood class\n",
    "        for i, c in enumerate(row):\n",
    "            probabilities = self.calcClassProb(c)\n",
    "            best_label, best_prob = None, -1\n",
    "            for class_value, probability in probabilities.items():\n",
    "                # list all probabilities each class and select the highest one\n",
    "                if best_label is None or probability > best_prob:\n",
    "                    best_prob = probability\n",
    "                    best_label = class_value\n",
    "            label.append(best_label)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayesClassifier()\n",
    "result = nb.fit(X_train,y_train)\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        14\n",
      "Iris-versicolor       1.00      0.82      0.90        17\n",
      " Iris-virginica       0.82      1.00      0.90        14\n",
      "\n",
      "       accuracy                           0.93        45\n",
      "      macro avg       0.94      0.94      0.94        45\n",
      "   weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Accuracy score:  0.9333333333333333\n",
      "Misclassified examples: 3\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.asarray(y_pred)\n",
    "\n",
    "target_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica' ]\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "print('Accuracy score: ', (y_test == y_pred).sum() / len(y_test))\n",
    "print('Misclassified examples: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineData(X, y):\n",
    "    dataset = []\n",
    "    for i in range(len(X)):\n",
    "        dataset.append(X[i].tolist()+[y[i]])\n",
    "    return dataset\n",
    "\n",
    "def crossValidationFold(dataset, folds=3):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = random.randrange(len(dataset_copy))\n",
    "            #index = range(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracyMetric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    " \n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def crossValidation(X, y, algorithm, n_folds, **kwargs):\n",
    "    dataset = combineData(X,y)\n",
    "    folds = crossValidationFold(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy.remove(row_copy[-1])\n",
    "       \n",
    "        y_pred = algorithm(train_set, test_set, **kwargs)\n",
    "        y_test = [row[-1] for row in fold]\n",
    "        accuracy = accuracyMetric(y_test, y_pred)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def naiveBayes(train_set, X_test):\n",
    "    y_train = [row[-1] for row in train_set]\n",
    "    X_train = [row[:-1] for row in train_set]\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    nb = NaiveBayesClassifier()\n",
    "    result = nb.fit(X_train,y_train)\n",
    "    y_pred = nb.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def decisionTree(train_set, X_test, max_depth=5):\n",
    "    y_train = [row[-1] for row in train_set]\n",
    "    X_train = [row[:-1] for row in train_set]\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "   \n",
    "    dt = DecisionTreeClassifier(max_depth)\n",
    "    result = dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [80.0, 86.66666666666667, 93.33333333333333, 100.0, 86.66666666666667, 100.0, 100.0, 93.33333333333333, 100.0, 100.0]\n",
      "Mean Accuracy: 94.000%\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "result = []\n",
    "\n",
    "random.seed(0)\n",
    "dt_scores =  crossValidation(X, y, decisionTree, n_folds = 10, max_depth = 8)\n",
    "print('Scores: %s' % dt_scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(dt_scores)/float(len(dt_scores))))\n",
    "result.append(dt_scores)\n",
    "names.append('Decision Tree: C4.5 Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [86.66666666666667, 93.33333333333333, 93.33333333333333, 100.0, 86.66666666666667, 100.0, 100.0, 100.0, 93.33333333333333, 100.0]\n",
      "Mean Accuracy: 95.333%\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "nb_scores =  crossValidation(X, y, naiveBayes, n_folds = 10)\n",
    "print('Scores: %s' % nb_scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(nb_scores)/float(len(nb_scores))))\n",
    "result.append(nb_scores)\n",
    "names.append('Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAf50lEQVR4nO3deZwcVb338c8XIktYswwIITFcjUouStQWkc0HiIjIw/aogChBgYgXLgJXL3r1BQjqhStccEOMkU0gJrJGBUxABFRAOpCEhICJrCEsgwmbAczye/6o01I23ZOZrpnMUt/369Wvrjp1Tp1TPTX9qzpVXUcRgZmZlc86vd0AMzPrHQ4AZmYl5QBgZlZSDgBmZiXlAGBmVlIOAGZmJeUAYN1C0iWSvtlD6z5c0owOlv8fSYt7ou7+TtJ/SZrc2+2wvskBwLpE0u8kLZO0/tqqMyKuiIi9c20ISW9bW/Urc4KkeZL+JmmxpF9IetfaakOrIuLbEXF0b7fD+iYHAOs0SaOB3YAA9l9LdQ5aG/WswXeBLwInAEOBtwPXAR/rzUatSR/57KwPcwCwrjgCuAu4BJjQUUZJ/ynpKUlLJB2dP2qXtJmkyyS1S3pM0tclrZOWHSnpD5LOk7QUOD2l/T4tvz1VMUfSy5IOydX5H5KeTfV+Npd+iaQLJN2YyvxB0pslnZ/OZh6U9J4m2zEGOA44LCJ+GxGvRcTydFZyVhe353lJD0vaOaU/kdo7oa6tF0qaKeklSbdJektu+XdTuRclzZK0W27Z6ZKuknS5pBeBI1Pa5Wn5BmnZX1Nb7pG0ZVq2taTpkpZKWiTpmLr1Tkvb+JKk+ZIqHf39rX9wALCuOAK4Ir0+UvvyqCdpH+BkYDzwNuBDdVm+D2wG/EtadgTw2dzyDwAPA1sA38oXjIjd0+QOEbFxRExN829O6xwBHAX8UNKQXNFPAl8HhgOvAXcC96b5q4D/bbLNewGLI+JPTZZ3dnvmAsOAK4GfA+8n+2w+DfxA0sa5/IcDZ6a2zSb7vGvuAcaRnYlcCfxC0ga55Qek7dm8rhxkQXszYGRqy7HAK2nZFGAxsDXwceDbkvbKld0/tXtzYDrwgw4+D+snHACsUyTtCrwFmBYRs4C/AJ9qkv2TwMURMT8ilgPfyK1nXeAQ4KsR8VJEPAqcC3wmV35JRHw/IlZGxCt0zgrgjIhYERE3AC8D78gtvzYiZkXEq8C1wKsRcVlErAKmAg3PAMi+KJ9qVmknt+eRiLg4V9fI1NbXImIG8HeyYFDz64i4PSJeA74GfFDSSICIuDwi/po+m3OB9eu2886IuC4iVjf47Fak7XlbRKxKn8eLad27AqdExKsRMRuYXLcNv4+IG9I2/AzYodlnYv2HA4B11gRgRkQ8l+avpHk30NbAE7n5/PRwYD3gsVzaY2RH7o3yd9ZfI2Jlbn45kD+qfiY3/UqD+Xzef1ovsFUH9XZme+rrIiI6qv8f2x8RLwNLyT7TWjfXAkkvSHqe7Ih+eKOyDfwM+A3w89Q19z+S3pTWvTQiXupgG57OTS8HNvA1hv7PAcDWSNKGZEf1H5L0tKSngZOAHSQ1OhJ8CtgmNz8yN/0c2ZHoW3Jpo4Anc/N96RG1twDbdNDn3Znt6ap/fF6pa2gosCT1959C9rcYEhGbAy8AypVt+tmls6NvRMRYYGdgP7LuqiXAUEmbdOM2WD/gAGCdcSCwChhL1v88DtgOuIPsC6TeNOCzkraTNBg4tbYgdSFMA74laZN0gfNk4PIutOcZsv72HhcRC4ELgCnKfm+wXrqYeqikr3TT9tTbV9KuktYjuxZwd0Q8AWwCrATagUGSTgU27exKJe0h6V2p2+pFssC1Kq37j8B/p217N9l1lPprCDbAOABYZ0wg69N/PCKerr3ILgQeXt8VEBE3At8DbgUWkV1wheziK8C/A38ju9D7e7LupIu60J7TgUvTnSyfbHGbuuIEsm39IfA82fWPg4BfpuVFt6felcBpZF0/7yO7KAxZ982NwJ/JumhepWvdZW8mu0D8IrAAuI3XA9VhwGiys4FrgdMiYmaBbbB+QB4QxnqapO2AecD6df30VkfSJWR3HX29t9tiA5/PAKxHSDoodZcMAc4Gfukvf7O+xQHAesrnyfqq/0J2/eALvdscM6vnLiAzs5LyGYCZWUk5AJiZlZQDgJlZSTkAmJmVlAOAmVlJOQCYmZWUA4CZWUk5AJiZlZQDgJlZSTkAmJmVlAOAmVlJOQCYmZWUA4CZWUk5AJiZldSgNWfpO4YPHx6jR4/u7WaYmfUbs2bNei4i2hot61cBYPTo0VSr1d5uhplZvyHpsWbL3AVkZlZSDgBmZiXlAGBmVlIOAGZmJeUAYGZWUmsMAJIukvSspHm5tKGSZkpamN6HpHRJ+p6kRZLmSnpvk3W+T9L9Kd/3JKn7NsnMzDqjM2cAlwD71KV9BbglIsYAt6R5gI8CY9JrIvCjJuv8UVpey1u/fjMz62FrDAARcTuwtC75AODSNH0pcGAu/bLI3AVsLmmrfME0v2lE3BkRAVyWK29mZmtJq9cAtoyIpwDS+xYpfQTwRC7f4pSWNyKld5TnHyRNlFSVVG1vb2+xuQPf0KFDkdSjr6FDh/b2Zlo/5H2z7+ruXwI36suPFvK8viBiEjAJoFKpNM1XdsuWLSM7oeo5vlRjrfC+2Xe1egbwTK1rJ70/m9IXAyNz+bYBltSVXZzSO8pjZmY9rNUAMB2YkKYnANfn0o9IdwPtBLxQ6yqqSfMvSdop3f1zRK68mZmtJZ25DXQKcCfwDkmLJR0FnAV8WNJC4MNpHuAG4GFgEfAT4N9y65mdW+0XgMkp31+AG4tvipmZdcUarwFExGFNFu3VIG8AxzVZz7jcdBXYvpNtNDOzHuBfApuZlZQDgJlZSTkAmJmVlAOAmVlJOQCYmZWUA4CZWUk5AJiZlZQDgJlZSTkAmJmVlAOAmVlJOQCYmZWUA4CZWUk5AJiZlZQDgJlZSTkAmJmVlAOAmVlJFRoUXtIXgWPIBnr/SUScL2kq8I6UZXPg+fxgMLmyjwIvAauAlRFRKdIWMzPrmpYDgKTtyb78dwT+Dtwk6dcRcUguz7nACx2sZo+IeK7VNpiZWeuKdAFtB9wVEcsjYiVwG3BQbWEa8P2TwJRiTTQzs55QJADMA3aXNEzSYGBfYGRu+W7AMxGxsEn5AGZImiVpYrNKJE2UVJVUbW9vL9BcMzPLa7kLKCIWSDobmAm8DMwBVuayHEbHR/+7RMQSSVsAMyU9GBG3N6hnEjAJoFKpRKvtNTOzf1boLqCI+GlEvDcidgeWAgsBJA0CDgamdlB2SXp/FriW7FqCmZmtJYUCQDp6R9Iosi/82hH/eODBiFjcpNxGkjapTQN7k3UpmZnZWlLoNlDgaknDgBXAcRGxLKUfSl33j6StgckRsS+wJXBtdp2YQcCVEXFTwbaYmVkXFAoAEbFbk/QjG6QtIbtQTEQ8DOxQpG4zMyvGvwQ2MyspBwAzs5Iqeg3A+og4bVM4fbOer8Osi7xv9l2K6D+31lcqlahWq73djD5JEj39t1wbddjA432zd0ma1exZa+4CMjMrKQcAM7OScgAwMyspBwAzs5JyADAzKykHADOzknIAMDMrKQcAM7OScgAwsz6lfXk7R950JM+94uHCe5oDgJn1KRfOvZB7n7mXC+dc2NtNGfAcAMysz2hf3s71i64nCK5bdJ3PAnpY0RHBvihpnqT5kk5MaadLelLS7PTat0nZfSQ9JGmRpK8UaYeZDQwXzr2Q1bEagNWx2mcBPazlACBpe+AYsrF8dwD2kzQmLT4vIsal1w0Nyq4L/BD4KDAWOEzS2FbbYmb9X+3of8XqFQCsWL3CZwE9rMgZwHbAXRGxPCJWArcBB3Wy7I7Aooh4OCL+DvwcOKBAW8ysn8sf/df4LKBnFQkA84DdJQ2TNJhsuMeRadnxkuZKukjSkAZlRwBP5OYXpzQzK6k5z875x9F/zYrVK5j97OxeatHA1/KAMBGxQNLZwEzgZWAOsBL4EXAmEOn9XOBzdcXVaJWN6pE0EZgIMGrUqFaba2Z93FX7X9XbTSidQheBI+KnEfHeiNgdWAosjIhnImJVRKwGfkLW3VNvMa+fLQBsAyxpUsekiKhERKWtra1Ic83MLKfoXUBbpPdRwMHAFElb5bIcRNZVVO8eYIykbSWtBxwKTC/SFjMz65qiYwJfLWkYsAI4LiKWSfqZpHFkXTqPAp8HkLQ1MDki9o2IlZKOB34DrAtcFBHzC7bFzMy6oFAAiIjdGqR9pkneJWQXimvzNwBvuEXUzMzWDv8S2MyspBwAzMxKygGghPy0RTMDB4BS8tMWzQwcAErHT1s0sxoHgJLx0xbNrMYBoET8tEUzy3MAKBE/bdHM8hwASsRPWzSzvKKPgrB+xE9bNLM8nwGYmZWUzwDMrMdJjYYA6T5DhjQad8rWxAHAzHpURMOxnjokqaVy1jXuAjIzKykHADOzknIAMDMrqaJDQn5R0jxJ8yWdmNK+I+lBSXMlXStp8yZlH5V0v6TZkqpF2mFmZl3XcgCQtD1wDNmg7zsA+0kaA8wEto+IdwN/Br7awWr2iIhxEVFptR1mZtaaImcA2wF3RcTyiFgJ3AYcFBEz0jzAXcA2RRtpZmbdr0gAmAfsLmmYpMFk4/2OrMvzOeDGJuUDmCFplqSJzSqRNFFSVVK1vb29QHPNzCyv5d8BRMQCSWeTdfm8DMwBakf+SPpamr+iySp2iYglkrYAZkp6MCJub1DPJGASQKVS8Y3BZmbdpNBF4Ij4aUS8NyJ2B5YCCwEkTQD2Aw6PJr/miIgl6f1Z4FqyawlmZraWFL0LaIv0Pgo4GJgiaR/gFGD/iFjepNxGkjapTQN7k3UpmZnZWlL0URBXSxoGrACOi4hlkn4ArE/WrQPZheJjJW0NTI6IfYEtgWvT8kHAlRFxU8G2mJlZFxQKABGxW4O0tzXJu4TsQjER8TDZraNmZtZL/EtgM7OScgAwMyspBwAzs5JyADAzKykHADOzknIAMDMrKQcAM7OScgAwMyspBwAzs5JyADAzKykHADOzknIAMDMrKQcAM7OScgAwMyspBwAzs5JyADAzK6miQ0J+UdI8SfMlnZjShkqaKWlheh/SpOyElGdhGkPYzMzWopYDgKTtgWPIBnPfAdhP0hjgK8AtETEGuCXN15cdCpwGfCCVP61ZoDAzs55R5AxgO7LxfpdHxErgNuAg4ADg0pTnUuDABmU/AsyMiKURsQyYCexToC1mZtZFRQLAPGB3ScMkDSYb73cksGVEPAWQ3rdoUHYE8ERufnFKewNJEyVVJVXb29sLNNfMzPJaDgARsQA4m+zo/SZgDrCyk8XVaJVN6pkUEZWIqLS1tbXUVjMze6NCF4Ej4qcR8d6I2B1YCiwEnpG0FUB6f7ZB0cVkZws12wBLirTFzMy6puhdQFuk91HAwcAUYDpQu6tnAnB9g6K/AfaWNCRd/N07pZmZ2VoyqGD5qyUNA1YAx0XEMklnAdMkHQU8DnwCQFIFODYijo6IpZLOBO5J6zkjIpYWbIuZmXWBIhp2vfdJlUolqtVqbzejT5JET/8t10YdZuB9rTtJmhURlUbL/EtgM7OScgAwMyspBwAzs5JyADAzKykHADOzknIAMDMrKQcAM7OScgAwMyspBwAzs5JyADAzKykHADOzkir6MDjrQ6RGwyx0nyFDPGqn2UDiADBAdPXBWX7Ylpm5C8jMrKQcAMzMSqpQF5Ckk4CjycbzvR/4LNkYwZukLFsAf4qIAxuUXZXKADweEfsXaYuZmXVNywFA0gjgBGBsRLwiaRpwaETslstzNY2HhAR4JSLGtVq/mZkVU7QLaBCwoaRBwGByA7tL2gTYE7iuYB1mZtYDWg4AEfEkcA7ZuL9PAS9ExIxcloOAWyLixSar2EBSVdJdkt7QRWRmZj2r5QAgaQhwALAtsDWwkaRP57IcBkzpYBWj0jiVnwLOl/TWJvVMTIGi2t7e3mpzzcysTpEuoPHAIxHRHhErgGuAnQEkDQN2BH7drHBELEnvDwO/A97TJN+kiKhERKWtra1Ac83MLK9IAHgc2EnSYGU/Qd0LWJCWfQL4VUS82qigpCGS1k/Tw4FdgAcKtMXMzLqoyDWAu4GrgHvJbudcB5iUFh9KXfePpIqkyWl2O6AqaQ5wK3BWRDgAmJmtRepPjwOoVCpRrVZ7uxkDgh8FYX2Z98/uI2lWut76Bv4lsJlZSTkAmJmVlAOAmVlJ+XHQZtYr1jR+RbPlvjbQfRwAzKxX+Iu897kLyMyspBwAzMxKygHAzKykHADMzErKAcDMrKQcAMzMSsoBwMyspBwAzMxKygHAzKykHADMzErKAcDMrKQKBQBJJ0maL2mepCmSNpB0iaRHJM1Or3FNyk6QtDC9JhRph5mZdV3LD4OTNAI4ARgbEa9ImkY2FCTAlyPiqg7KDgVOAypAALMkTY+IZa22x8zMuqZoF9AgYENJg4DBwJJOlvsIMDMilqYv/ZnAPgXbYmZmXVBkUPgngXOAx4GngBciYkZa/C1JcyWdJ2n9BsVHAE/k5hentDeQNFFSVVK1vb291eaamVmdlgOApCHAAcC2wNbARpI+DXwVeCfwfmAocEqj4g3SGj4cPCImRUQlIiptbW2tNtfMzOoU6QIaDzwSEe0RsQK4Btg5Ip6KzGvAxcCODcouBkbm5reh891HZmbWDYoEgMeBnSQNVjZ2217AAklbAaS0A4F5Dcr+Bthb0pB0JrF3SjMzs7Wk5buAIuJuSVcB9wIrgfuAScCNktrIunlmA8cCSKoAx0bE0RGxVNKZwD1pdWdExNIC22FmZl2k/jQuZ6VSiWq12tvNGBAkeUxWsxKQNCsiKo2W+ZfAZmYl5QBgZlZSDgBmZiXlAGBmVlIOAGZmJeUAYGZWUg4AZmYl5QBgZlZSDgBmZiXlAGBmVlIOAGZmJeUAYGZWUg4AZmYl5QBgZlZSDgBmZiXlAGBmVlKFAoCkkyTNlzRP0hRJG0i6QtJDKe0iSW9qUnaVpNnpNb1IO8zMrOtaDgCSRgAnAJWI2B5YFzgUuAJ4J/AuYEPg6CareCUixqXX/q22w8zMWtPymMC58htKWgEMBpZExIzaQkl/ArYpWIeZmfWAls8AIuJJ4BzgceAp4IW6L/83AZ8Bbmqyig0kVSXdJenAZvVImpjyVdvb21ttrpmZ1SnSBTQEOADYFtga2EjSp3NZLgBuj4g7mqxiVBqo+FPA+ZLe2ihTREyKiEpEVNra2lptrpmZ1SlyEXg88EhEtEfECuAaYGcASacBbcDJzQpHxJL0/jDwO+A9BdpiZmZdVCQAPA7sJGmwJAF7AQskHQ18BDgsIlY3KihpiKT10/RwYBfggQJtMTOzLipyDeBu4CrgXuD+tK5JwIXAlsCd6RbPUwEkVSRNTsW3A6qS5gC3AmdFhAOAmdlapIjo7TZ0WqVSiWq12tvNGBAk0Z/+9mbWGkmz0vXWN/Avgc3MSsoBwMyspBwAzMxKygHAzKykHADMzErKAcDMrKQcAMzMSsoBwMyspBwAzMxKygHAzKykHADMzErKAcDMrKQcAMzMSsoBwMyspBwAzMxKygHAzKykCgUASSdJmi9pnqQpkjaQtK2kuyUtlDRV0npNyn5V0iJJD0n6SJF2mJlZ17UcACSNAE4AKhGxPbAucChwNnBeRIwBlgFHNSg7NuX9V2Af4AJJ67baFjMz67qiXUCDgA0lDQIGA08Be5KNFQxwKXBgg3IHAD+PiNci4hFgEbBjwbaYmVkXFBkU/kngHOBxsi/+F4BZwPMRsTJlWwyMaFB8BPBEbr5ZPiRNlFSVVG1vb2+1uaUlqeGro2W15WY2sBXpAhpCdiS/LbA1sBHw0QZZG4083ugbpuEI5RExKSIqEVFpa2trtbmlFREtvcxs4CvSBTQeeCQi2iNiBXANsDOweeoSAtgGWNKg7GJgZG6+WT4zM+shRQLA48BOkgYr6zPYC3gAuBX4eMozAbi+QdnpwKGS1pe0LTAG+FOBtpiZWRcVuQZwN9nF3nuB+9O6JgGnACdLWgQMA34KIGl/SWeksvOBaWQB4ybguIhYVWA7zMysi9Sf+nsrlUpUq9XeboaZWb8haVZEVBot8y+BzcxKygHAzKykHADMzErKAcDMrKT61UVgSe3AY73djgFiOPBcbzfCrAnvn93nLRHR8Fe0/SoAWPeRVG12Z4BZb/P+uXa4C8jMrKQcAMzMSsoBoLwm9XYDzDrg/XMt8DUAM7OS8hmAmVlJDcgAIGmVpNlpvOI5kk6W1NK2SjpD0vgOlh8r6YjWWwuS3pXaO1vSUkmPpOmbi6y3k3V/TNIsSQ9IelDS2XXLD5UUksY1Kb9Y0v2pvXevoa55kn5Wl3a5pEajxnWZpA9IOi9N7ylpp56op0zS3/7c3PyXJJ2+hjL7S/pKN9R9pKT23P/yVZIGF12vvW7QmrP0S69ExDgASVsAVwKbAad1dUURceoall/YUgv/eR33A7X2XgL8KiKuqs8naVButLXCJO0AnA98LCL+nMZxOCa3fFPg34A1PYFvt4h4fg11vRtYCewpacOIeKVY69+w/kHpCbW1ILQn2X3kd3VnPSX0GnCwpP+OiE7dlx8R08ke+d4dpkbE8QCSrgQOAS7upnWX3oA8A8iLiGeBicDxyqwr6TuS7pE0V9Lna3kl/Wc6mp0j6ayUdomkj6fps9KR8lxJ56S00yV9KU2Pk3RXWn5tGjUNSb+TdLakP0n6s6TdOtt+SeMl3Szp58B9KW1CWtdsSRfUzm4kfVTSnZLulTRV0kZrWP0pwJkR8ef0Wa2MiB/lln87vV7rbHs7cBhwGfBbYL9GGdKR40OS7pD0fUnXpfThkqanz/WPkrZP6d+U9GNJM4GL02d1naS3AkcDX06f0c6pij1S+YclHZTWMV7SrenocmFa5xG5/WN0N2x7f7aS7ILsSfULJP1fSXdLui/to1um9CMl/UDSZpIeze2fgyU9IelNkt4q6SZlZ593SHpnR41IBycbAcua1S1pnfQ3bEt51pG0KO0/bZKuTn/XeyTtkvJ8SK+ffd8naZPu/PD6vFaHDOzLL+DlBmnLgC3JgsHXU9r6ZEe325INZ/lHYHBaNjS9X0I2wM1Q4CFev3C+eXo/HfhSmp4LfChNnwGcn6Z/B5ybpvcFbu6g7ZcAH8/NjwdeBkal+e2B64BBaX4S8ClgC+C2XPu/BvxXmv4WsG+DuuYC/9qkHe8HpqXp3wPjmuR7gmxMiFnAUR1s11/Ixn3eF7gml345cCAwmGykuLeQDRn6C+C6lOdHwNfS9N5ANU1/k2wgoQ1yn9V1uWUn1tUzJa373cCDuTJL076xAfA0cGpa9h/AOb29P/f2/xKwKfAo2Vn0l4DT07Ihuf+Ho3P7+JHAD9L09cAeafoQYHKavgUYk6Y/APy2Qd1HAu3AbOAZ4A5g3TXUfVrt7572lavT9JXArml6FLAgTf8S2CVNb0z6vyrLa6B2ATVSG4d4b+DdtaN6sp16DNkXwcURsRwgIpbWlX8ReBWYLOnXwK/+aeXSZmRB4baUdCnZl1jNNel9FjC6i22/MyIeT9Pjyb6cq8oGb9+Q7Et4OTAW+GNKX4/si5uI+FpXKktHbOcCn+5E9g9ExBJJbwZmSloQEX+sW98HgcUR8aSkZ4GfSNosIl7IZRsLPBQRj6UyU4DatZVdgY+lbZmRzspqZzfXR8Srndy06yL7T58raUQu/e6IeCbV+zDwm5R+P/DBTq57wIqIFyVdBpwA5LvutgGmStqKbH97pEHxqWRf/LcChwIXSNqYbPjYX6R9FbKDsUamRsTxyjL+EPgycFYHdV9EFnTOBz7H691F44Gxufo2TUf7fwD+V9IVZAcmizvxkQwYA74LCEDSvwCrgGfJAsG/R8S49No2Imak9Kb3xEbW974jcDXZEetNXWxGrRtlFV2/9vK33LSAi3Ltf0dEnJnSb8qlj42IiWtY73zgfQ3SNyf7Qr5d0qNABbhB0nvqM0bEkvT+NNk/3o4N1ncYsH1a10KyI8qD6vKovlAHy/Lzf6Pz8l1ZapK+Oje/moF7nayrzgeOIuuGqfk+2ZH+u4DPk51B1ZsOfFTSULJ97bdk3zvP5/bVcRGxXUeVp8D9S2D3juqOiCeAZyTtSXZmcWPKvw7wwVx9IyLipYg4i+wMYkPgrjV1RQ00Az4ApP7AC8l2liA7uvuCpDel5W9PR5MzgM8p3WWQdtj8ejYGNouIG4ATSRdta9LR7LJc//5nyLpkutvNwCclDU/tGiZpFFn31YdSsEPSRpLGrGFd/wN8XdLbUpl1JZ0cEUsjYnhEjI6I0WTdZPtGxH35wpI2Tp9L7fP5MDCvLs+6wP8DxubWdzBZUMibD7xD0sh0tHdIbtntwOFpfePJzibW9MX/ElCu/twelM6Ip5EFgZrNgCfT9IQm5V4m66b7LtnNDasi4kXgEUmfAFBmh040Y1eyrsQ11T2ZrMtvWrw+1OwM4PhaBqW72iS9NSLuj4izyfZzB4ABYMN0UWc+2RfmDOAbadlksrGI75U0D/gxWb/fTWRHK1VJs8n6OvM2AX4laS7ZF/sbLoqR7YjfSXnGkV0H6FaR3TH0DeDmVM8MYMvUhXEU2WnxHLKA8HYASd+StG+Ddd1Htp3TJC0g6/Jo+NTAmvQFXbvDYyvgD6m+u4FrI6L+1tU9gEdqXSzJrcC42kXD1JblZP+gN5P19S4Bal1EpwI7p+09A/hsR21MricLlPfp9YvAVsy5ZE/prDmdrBvnDjp+cudUsu7Eqbm0w4Gj0r4zHzigSdlD0v/yXOA9wJmdqHs6WX9+/m6hE4CKsgv7DwDHpvQTld2ePIese+tGSsS/BLY+Q9LGEfFyOgP4MXB/RHy/t9tl/YukCnBeRHT6bruyGqhnANY/fSGdfT1A1if7k15uj/Uzyn6AdjXw1d5uS3/gMwAzs5LyGYCZWUk5AJiZlZQDgJlZSTkAmJmVlAOAmVlJOQCYmZXU/wdROYCvQs4evwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot Graph\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(result, showmeans=True)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar Graph\n",
    "n_groups = 10\n",
    "\n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, dt_scores, bar_width,\n",
    "                 alpha=opacity,color='b',label='Decision Tree (C4.5)')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, nb_scores, bar_width,\n",
    "                 alpha=opacity,color='g',label='Naive Bayes')\n",
    "\n",
    "plt.xlabel('Training #')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.xticks(index + bar_width, ('1', '2', '3', '4', '5',\n",
    "                               '6', '7', '8', '9', '10'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
